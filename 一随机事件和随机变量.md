# 一、随机事件

## 1.基本概念

- <font color=blue>随机现象</font>：现实生活中，一个动作或一件事情，在一定条件下，所得的结果不能预先完全确定，只能是多种可能结果中的一种。

- <font color=blue>随机实验(记为$E$)</font>:实现随机现象并对它进\行观察的全过程。随机实验满足以下三个条件：

  1）可在相同条件下重复进行；

  2）所有可能结果不唯一，且已知；

  3）每次试验的结果事先不能确定。

- <font color=blue>样本空间(记为$\Omega$)</font>:随机实验的<font color=red>所有可能结果</font>组成的集合。

- <font color=blue>样本点(记为$\omega$)</font>:试验的<font color=red>每一个可能结果</font>。

- <font color=blue>随机事件(用大写字母$A,B,C...$)</font>:样本空间$\Omega$中满足一定条件的子集。随机事件在随机实验中可能出现也可能不出现。

- <font color=blue>必然事件</font>:$\Omega$为必然事件。因为样本空间$\Omega$包含了所有的样本点。在试验中，称一个事件发生是指构成该事件的一个样本点出现。

- <font color=blue>不可能事件</font>:空集$\phi$不包含任何样本点，且在每次试验中总不发生，为不可能事件。

## 2.概率

### 1.定义

随机试验$E$的样本空间为$\Omega$，对于每个事件$A$，定义一个实数$P(A)$与之对应，若函数$P(.)$满足条件：

1. 对每个事件A，均有$0<P(A)<=1$;
2. $P(\Omega)=1$;
3. 若事件$A_1,A_2,A_3,...$两两互斥，即对于$i,j=1,2,...i \neq j,A_i \cup A_j=\phi$，均有$P(A_1 \cup A_2 \cup ...)=P(A_1) + P(A_2) +...$

则称$P(A)$为事件$A$的<font color=blue>概率</font>。

### 2.主要性质

- 对于任一事件$A$，均有$P(\overline{A})=1-P(A)$.
- 对于两个事件$A$和$B$，若$A \subset B$，则有$P(B-A)=P(B)-P(A),P(B)>P(A)$.
- 对于任意两个事件$A$和$B$，有$P(A \cup B)=P(A)+P(B)-P(A \cap B)$.

### 3.古典概型

设随机事件$E$的样本空间只有<font color=red>有限个样本点</font>，即$\Omega={\omega_1,\omega_2,...,\omega_n}$，其中，$n$为样本点的总数。每个样本点$w_i(i=1,2,...,n)$出现是<font color=red>等可能的</font>，并且每次试验有且仅有一个样本点发生，则称这类现象为<font color=blue>古典概型</font>。

若事件$A$包含了$m$个样本点，则事件$A$的概率为：
$$
P(A) = \frac{m}{n} = \frac{事件A包含的基本事件数}{基本事件总数}。
$$


### 4.条件概率

设$A$和$B$是两个事件，且$P(B)>0$，称$P(A|B) = \frac{P(AB)}{P(B)}$是在事件$B$发生的条件下，事件$A$发生的概率。

### 5.全概率公式和贝叶斯公式

<font color=blue>概率乘法公式</font>：$P(AB)=P(B|A)P(A)=P(A|B)P(B)$

<font color=blue>样本空间划分</font>:事件组$B_1,B_2,...$是样本空间$\Omega$的一个划分，需要满足以下条件：

​	1）$B_1,B_2,...$两两互斥，即$B_i \cap B_j = \phi, i \neq j,i,j=1,2,...$且$P(B_i)>0,i=1,2,...$

​	2)$B_1 \cup B_2 \cup...=\Omega$

**<font color=blue>全概率公式</font>**

设$B_1,B_2,...$是样本空间$\Omega$的一个划分，$A$为任一事件，则$P(A)=\sum_{i=1}^{\infty}{P(B_i)P(A|B_i)}$

**<font color=blue>贝叶斯公式</font>重中之重**

设$B_1,B_2,...$是样本空间$\Omega$的一个划分，则对任一事件$A(P(A)>0)$，有
$$
P(B_i|A)= \frac{P(B_iA)P(B_i)}{\sum_{i=0}^{\infty}{P(B_i)P(A|B_i)}},i=1,2,...
$$
其中$P(B_i)(i=1,2,...)$为先验概率，$P(B_i|A)(i=1,2,...)$为后验概率。

# 二、随机变量

## 1.随机变量及其分布

**<font color=blue>随机变量</font>**

设$E$是随机试验，$\Omega$是样本空间，如果对于每一个$\omega \in \Omega$。都有一个确定的实数$X(\omega)$与之对应，若对于任意实$x \in R$，有${\omega: X(\omega)<x} \in F$，则称$\Omega$上的单值实函数$X(\omega)$为一个随机变量。

随机变量是定义在样本空间$\Omega$上，取值在实数域上的函数。

自变量是随机试验的结果，随机试验结果的出现具有随机性，因此随机变量的取值也具有一定的<font color=blue>随机性</font>。

**<font color=blue>随机变量的分布函数</font>**

设$X$是一个随机变量，对任意的实数$x$，令$F(x)=P(X<=x),x\in(-\infty,+\infty)$，称$F(x)$是随机变量$x$的分布函数，也称概率累积函数。

**<font color=blue>离散型随机变量</font>**

如果随机变量 $X$ 的全部可能取值只有有限多个或可列无穷多个，则称 $X$ 为离散型随机变量。掷骰子的结果就是离散型随机变量。

对于离散型随机变量 $X$ 可能取值为 $x_k$的概率为：$P \{ X =x_k \} =p_k,k=1,2,...$

可以使用下表进一步表示分布律：

|  $X$  | $x_1$ | $x_2$ | ...  | $x_n$ | ...  |
| :---: | :---: | :---: | :--: | :---: | :--: |
| $P_k$ | $p_1$ | $p_2$ | ...  | $p_n$ | ...  |

离散型随机变量的分布函数为：
$$
F (x) = P \{  X<=x \} =\sum_{x_k <=x}{ P \{  X=x_k \} } = \sum_{x_k <=x}{ P_k}
$$
**<font color=blue>常用的离散型分布</font>**

**1.伯努利实验、二项分布**

<font color=blue>Bernoulli(伯努利)试验</font>:一个随机试验只有两种可能的结果$A$和$\overline A$，并且$P(A)=p,P(\overline{A})=1-p=q$，其中，$0<p<1$

<font color=blue>n重伯努利试验</font>:Bernoulli试验独立重复进行$n$次。

## 2.随机变量的数字特征

<font color=blue>数学期望</font>

- <font color=blue>离散型</font>：设离散型随机变量 $X$ 的分布律为 $P \{  X=x_i\} = p_i ,i =1，2，...，$ 若级数 $ \sum_{i} {|x_i|p_i}$ 收敛，则称级数 $ \sum_{i} {x_ip_i}$  的和为随机变量 $X$ 的数学期望。记为 $E(X)$ ,即：
  $$
  E(X) = \sum_{i} {x_ip_i}
  $$

- <font color=blue>连续型</font>：设连续型随机变量 $X$ 的概率密度函数为 $f(x)$ ,若积分 $\int_{- \infty}^{+ \infty}{|x|f（x）}dx$ 收敛， 称积分 $\int_{- \infty}^{+ \infty}{xf（x）}dx$ 的值为随机变量 $X$ 的数学期望，记为 $E(X)$ ,即：
  $$
  E(X)=  \int_{- \infty}^{+ \infty}{xf（x）}dx
  $$

$E(X)$又称为均值。

数学期望代表了随机变量取值的平均值，具有如下性质：

1. 若c是常数，则 $E(c) =c$ ;
2. $E(aX+bY) = aE(X) +bE(Y)$ , 其中a, b为任意常数；
3. 若 $X, Y$ 相互独立，则$E(XY) = E(X)E(Y)$ ; 

<font color=blue>方差</font>

设 $X$ 为随机变量，如果 $E\{  [X-E(X)]^2\} $ 存在，则称 $E\{  [X-E(X)]^2\} $ 为 $X$ 的方差。记为 $Var(X)$ , 即：$Var （X） =E\{  [X-E(X)]^2\}$

<font color=blue>标准差或均方差</font>

 $ \sqrt{Var(X)} $  为 $X$ 的标准差或均方差。

方差是用来描述随机变量取值相对于均值的离散程度的一个量，具有如下性质:

1. 若 $c$ 是常数，则 $Var(c) =0$ ;
2. $Var(aX+b) = a^2E(X)  $ , 其中a, b为任意常数；
3. 若 $X, Y$ 相互独立，则$Var(X+Y) = Var(X) +Var(Y)$ 。

<font color=blue>协方差和相关系数</font>

协方差和相关系数都是描述随机变量 $X$ 与随机变量 $Y$ 之间的线性联系程度的数字量。

- <font color=blue>协方差</font>:设 $X, Y$ 为两个随机变量，称 $ E\{  [X-E(X)] [Y-E(Y)]\} $ 为 $X$ 和 $Y$ 的协方差，记为 $Cov(X, Y)$，即：$Cov(X, Y) = E\{  [X-E(X)] [Y-E(Y)]\}$

  协方差的性质：

  1. $Cov(X, Y) = Cov(Y, X) $ ;
  2. $Cov(aX+b，cY+d) =ac Cov( X，Y) $ ,其中， $a,b,c,d$ 为任意常数；
  3. $Cov(X_1+X_2，Y) =Cov( X_1，Y) +Cov( X_2，Y) $ ;
  4. $Cov(X，Y) =E( X，Y) -E(X)E(Y) $ ;  当 $X,Y$ 相互独立时，有 $Cov(X，Y) = 0$;
  5. $|Cov(X，Y)| = \sqrt {Var(X)} \sqrt {Var(Y)} $ ; 
  6. $Cov(X，X) =Var( X) $ 

- <font color=blue>相关系数</font>:当 $ \sqrt {Var(X)}  >0 ，\sqrt {Var(Y)}  >0 $  时，$X,Y$的相关系数为$\rho（X,Y） = \frac{Cov(X，Y)}{\sqrt {Var(X)} \sqrt {Var(Y)}}$

  无量纲。<font color=red>使用相关系数衡量两个变量之间的相关程度。相关程度在-1到1之间，小于0表示负相关，大于0表示正相关。绝对值 $|\rho（X,Y）|$ 表示相关度的大小。越接近1，相关度越大。</font>